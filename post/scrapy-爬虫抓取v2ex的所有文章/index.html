<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Scrapy 爬虫抓取v2ex的所有文章 - 犀牛人家 - 感觉自己性格跟犀牛很像笨重而又却将倔强</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="changshou.wen" /><meta name="description" content="利用scrapy进行抓取v2ex的所有的文章，其中包含了基本的scrapy的用法，以及处理出现request 403错误的解决
" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.64.0 with theme even" />


<link rel="canonical" href="http://blog.54wcs.com/post/scrapy-%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96v2ex%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.61bcc626.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Scrapy 爬虫抓取v2ex的所有文章" />
<meta property="og:description" content="利用scrapy进行抓取v2ex的所有的文章，其中包含了基本的scrapy的用法，以及处理出现request 403错误的解决" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://blog.54wcs.com/post/scrapy-%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96v2ex%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/" />
<meta property="article:published_time" content="2020-02-11T14:31:10+08:00" />
<meta property="article:modified_time" content="2020-02-11T14:31:10+08:00" />
<meta itemprop="name" content="Scrapy 爬虫抓取v2ex的所有文章">
<meta itemprop="description" content="利用scrapy进行抓取v2ex的所有的文章，其中包含了基本的scrapy的用法，以及处理出现request 403错误的解决">
<meta itemprop="datePublished" content="2020-02-11T14:31:10&#43;08:00" />
<meta itemprop="dateModified" content="2020-02-11T14:31:10&#43;08:00" />
<meta itemprop="wordCount" content="1444">



<meta itemprop="keywords" content="python,爬虫," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Scrapy 爬虫抓取v2ex的所有文章"/>
<meta name="twitter:description" content="利用scrapy进行抓取v2ex的所有的文章，其中包含了基本的scrapy的用法，以及处理出现request 403错误的解决"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">犀牛之家</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">犀牛之家</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Scrapy 爬虫抓取v2ex的所有文章</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-02-11 </span>
        
          <span class="more-meta"> 约 1444 字 </span>
          <span class="more-meta"> 预计阅读 3 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#文件的目录">文件的目录</a></li>
    <li><a href="#创建爬虫项目">创建爬虫项目</a></li>
    <li><a href="#解决403的错误">解决403的错误</a></li>
    <li><a href="#最终元素的保存">最终元素的保存</a></li>
    <li><a href="#爬虫的代码">爬虫的代码</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>利用scrapy进行抓取v2ex的所有的文章，其中包含了基本的scrapy的用法，以及处理出现request 403错误的解决</p>
<h1 id="v2exscray">v2exScray</h1>
<p>项目代码全部上传到<a href="https://github.com/wenchangshou2/v2exScray">github</a>
这个项目的作用是将v2ex的所有的文章全部爬取下来最终抓取到的内容如下图所示
![屏幕快照 2016-05-19 下午4.16.05](<a href="http://o7ez1faxc.bkt.clouddn.com/2016-05-19-">http://o7ez1faxc.bkt.clouddn.com/2016-05-19-</a>屏幕快照 2016-05-19 下午4.16.05.png)</p>
<h2 id="文件的目录">文件的目录</h2>
<p><img src="http://o7ez1faxc.bkt.clouddn.com/2016-05-19-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-19%20%E4%B8%8B%E5%8D%883.57.30.png" alt="屏幕快照 2016-05-19 下午3.57.30"></p>
<h2 id="创建爬虫项目">创建爬虫项目</h2>
<p>scrapy创建工程的方式特别的简单，只要在shell下面输入下面的语句
![屏幕快照 2016-05-19 下午5.01.30](<a href="http://o7ez1faxc.bkt.clouddn.com/2016-05-19-">http://o7ez1faxc.bkt.clouddn.com/2016-05-19-</a>屏幕快照 2016-05-19 下午5.01.30.png)</p>
<p>执行成功之后会自动创建我们工程所需要的文件</p>
<p>![屏幕快照 2016-05-19 下午5.02.05](<a href="http://o7ez1faxc.bkt.clouddn.com/2016-05-19-">http://o7ez1faxc.bkt.clouddn.com/2016-05-19-</a>屏幕快照 2016-05-19 下午5.02.05.png)</p>
<h2 id="解决403的错误">解决403的错误</h2>
<p>在抓取的过程当中返回的都是403的错误，网站采用了防爬技术anti-web-crawling technique（Amazon所用),后来通过通过队列的形式随机更换user_aget来发送请求来解决这个问题</p>
<p>我们需要使用下面的rotate_useragent.py的代码来进行更换请求的头，同时需要在settings.py里面将DOWNLOADER_MIDDLEWARES的注释去掉并且进行更正成正确的引用</p>
<pre><code class="language-python">
DOWNLOADER_MIDDLEWARES = {
    'v2ex.rotate_useragent.RotateUserAgentMiddleware': 400,
}

</code></pre>
<p><strong>rotate_useragent.py文件的代码</strong></p>
<pre><code class="language-python">#!/usr/bin/python
#-*-coding:utf-8-*-

import random
from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

class RotateUserAgentMiddleware(UserAgentMiddleware):
    def __init__(self, user_agent=''):
        self.user_agent = user_agent

    def process_request(self, request, spider):
        #这句话用于随机选择user-agent
        ua = random.choice(self.user_agent_list)
        if ua:
            request.headers.setdefault('User-Agent', ua)

    #the default user_agent_list composes chrome,I E,firefox,Mozilla,opera,netscape
    #for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php
    user_agent_list = [\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;\
        &quot;Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1&quot;,\
        &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKithttp://o7ez1faxc.bkt.clouddn.com/2016-05-19-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-05-19%20%E4%B8%8B%E5%8D%884.16.05.png/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3&quot;,\
        &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;,\
        &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;
       ]
</code></pre>
<p>I## items配置
items.py里面定义了我们需要爬取的元素</p>
<pre><code class="language-python">from scrapy import Item,Field

class TencentItem(Item):
    title=Field() #文档标题
    url=Field()  #文章的链接

</code></pre>
<h2 id="最终元素的保存">最终元素的保存</h2>
<p>在scrapy里面会有一个piplines.py文章，爬虫会将抓取到的元素调用这个文件里面的函数进行存储</p>
<pre><code class="language-python">class JsonWithEncodingTencentPipeline(object):

    def __init__(self):
        self.file = codecs.open('v2ex.json', 'w', encoding='utf-8')#设置encoding来防止乱码

    def process_item(self, item, spider):
        line = json.dumps(dict(item), ensure_ascii=False) + &quot;\n&quot;#ensure_ascii为true的话输出的是一个ascii字符，想输出中文的话需要将其设置为False
        self.file.write(line)
        return item

    def spider_closed(self, spider):
        self.file.close(
)
</code></pre>
<h2 id="爬虫的代码">爬虫的代码</h2>
<pre><code class="language-python">
 rules = [
        Rule(
            sle(allow=(&quot;recent\?p=\d{1,5}&quot;)), follow=True, callback='parse_item')
    ]
</code></pre>
<p>下面是rule的源代码,当flollow为True的时候会自动调用 callback的函数</p>
<pre><code class="language-python">        if follow is None:
            self.follow = False if callback else True
        else:
            self.follow = follow
</code></pre>
<p>下面的是一篇文章的html的标记,我们现在需要取出所有div中class为&rsquo;cell item'的元素，然后进行遍历
然后再分别取出item_title的text和href的内容</p>
<pre><code class="language-html">&lt;div class=&quot;cell item&quot; style=&quot;&quot;&gt;
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; border=&quot;0&quot; width=&quot;100%&quot;&gt;
&lt;tr&gt;
&lt;td width=&quot;48&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;[
![](//cdn.v2ex.co/avatar/2dff/59fb/128998_normal.png?m=1446796863)](/member/jiangew)&lt;/td&gt;
&lt;td width=&quot;10&quot;&gt;&lt;/td&gt;
&lt;td width=&quot;auto&quot; valign=&quot;middle&quot;&gt;&lt;span class=&quot;item_title&quot;&gt;[
跳槽季：北京~Java~4 年~服务端码农](/t/279762#reply6)&lt;/span&gt;
&lt;div class=&quot;sep5&quot;&gt;&lt;/div&gt;
&lt;span class=&quot;small fade&quot;&gt;&lt;div class=&quot;votes&quot;&gt;&lt;/div&gt;[
Java](/go/java)  **[jiangew](/member/jiangew)** 2 分钟前  最后回复来自
**[feiyang21687](/member/feiyang21687)**&lt;/span&gt;
&lt;/td&gt;
&lt;td width=&quot;70&quot; align=&quot;right&quot; valign=&quot;middle&quot;&gt;
[6](/t/279762#reply6)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
</code></pre>
<p><strong>获取内容的代码</strong></p>
<pre><code class="language-python"> sites_even = sel.css('div.cell.item')

        for site in sites_even:
            item=TencentItem()
            item['title']=site.css('.item_title a').xpath('text()').extract()[0]
            item['url']='http://v2ex.com'+site.css('.item_title a').xpath('@href').extract()[0]

            items.append(item)

</code></pre>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">changshou.wen</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2020-02-11
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/python/">python</a>
          <a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/electron%E4%B8%8Ereact%E6%95%B4%E5%90%88/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Electron与react整合</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/shell-%E5%8A%A8%E6%80%81%E8%BF%9B%E7%A8%8B%E5%AE%88%E6%8A%A4/">
            <span class="next-text nav-default">Shell 动态进程守护</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  
  <div id="vcomments"></div>
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
  <script type="text/javascript">
    new Valine({
        el: '#vcomments' ,
        appId: '1QhU05cQQQjIVDFiUFqOrjmB-gzGzoHsz',
        appKey: '7I7EH0szenFgd1vjnxwFUPFp',
        notify:  false ,
        verify:  false ,
        avatar:'mm',
        placeholder: '说点什么吧...',
        visitor:  false 
    });
  </script>

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:wenchangshou@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/wenchangshou2" class="iconfont icon-github" title="github"></a>
  <a href="http://blog.54wcs.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">changshou.wen</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.de161082.min.js"></script>








</body>
</html>
